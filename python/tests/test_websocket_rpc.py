"""Test the hypha server."""

import asyncio
import time
from typing import Optional

import numpy as np
import pytest
import requests
import httpx
from hypha_rpc import (
    get_remote_service,
    connect_to_server,
    get_remote_service_sync,
    connect_to_server_sync,
    get_rtc_service,
    get_rtc_service_sync,
    login,
    login_sync,
    register_rtc_service,
    register_rtc_service_sync,
)

# Import Pydantic components for the test
try:
    from pydantic import BaseModel, Field
    from hypha_rpc.utils.pydantic import register_pydantic_codec

    HAS_PYDANTIC = True
except ImportError:
    HAS_PYDANTIC = False
    BaseModel = object  # Define a dummy BaseModel if pydantic is not installed

from . import WS_SERVER_URL

# Import schema_function for testing
from hypha_rpc.utils.schema import schema_function

# Define a simple Pydantic model for testing
if HAS_PYDANTIC:

    class TestData(BaseModel):
        """Some test data."""

        item_id: int = Field(..., description="The ID of the item")
        name: str = Field(..., description="The name of the item")
        price: float
        is_offer: Optional[bool] = Field(None, description="Whether this is an offer")

    @schema_function
    def process_test_data(data: TestData) -> str:
        """Processes the provided test data."""
        return f"Processed {data.name} with price {data.price}"


@schema_function
def add_numbers(a: int, b: float = 3.14) -> float:
    """Adds two numbers, an integer and a float."""
    return a + b


# Define a simple Pydantic model for testing
class TestModel(BaseModel):
    name: str
    value: int
    is_active: bool = True
    tags: list[str] = Field(default_factory=list)


class ImJoyPlugin:
    """Represent a test plugin."""

    def __init__(self, ws):
        """Initialize the plugin."""
        self._ws = ws

    # async def setup(self):
    #     """Set up the plugin."""
    #     await self._ws.log("initialized")

    async def run(self, ctx):
        """Run the plugin."""
        await self._ws.log("hello world")

    async def add(self, data):
        """Add function."""
        return data + 1.0


@pytest.mark.asyncio
async def test_schema(websocket_server):
    """Test schema."""
    api = await connect_to_server(
        {"name": "my app", "server_url": WS_SERVER_URL, "client_id": "my-app"}
    )
    for k in api:
        if callable(api[k]):
            assert (
                hasattr(api[k], "__schema__") and api[k].__schema__ is not None
            ), f"Schema not found for {k}"
            assert api[k].__schema__.get("name") == k, f"Schema name not match for {k}"


@pytest.mark.asyncio
async def test_service_with_builtin_key(websocket_server):
    """Test schema."""
    async with connect_to_server(
        {
            "name": "my app",
            "server_url": WS_SERVER_URL,
            "client_id": "my-app",
        }
    ) as api:
        data = {}
        info = await api.register_service(
            {
                "name": "Dictionary Service",
                "id": "dict-service",
                "description": "A service to store key-value pairs",
                "config": {
                    "visibility": "protected",
                    "run_in_executor": True,
                },
                "put": lambda k, v: data.update({k: v}),
                "get": lambda k: data.get(k),
                "pop": lambda k: data.pop(k),
                "keys": lambda: list(data.keys()),
                "values": lambda: list(data.values()),
                "items": lambda: [("key1", "value1"), ("key2", "value2")],
            }
        )
        assert "/" in info["id"] and ":" in info["id"], "Service id should be absolute"
        svc = await api.get_service("dict-service")
        await svc.put("key", "value")
        assert await svc.get("key") == "value"
        assert await svc.keys() == ["key"]
        assert await svc.values() == ["value"]
        assert await svc.pop("key") == "value"
        assert await svc.get("key") == None
        assert await svc.items() == [["key1", "value1"], ["key2", "value2"]]


@pytest.mark.asyncio
async def test_login(websocket_server):
    """Test login to the server."""
    TOKEN = "sf31df234"

    async def callback(context):
        print(f"By passing login: {context['login_url']}")
        loop = asyncio.get_running_loop()
        await loop.run_in_executor(
            None,
            requests.get,
            context["report_url"] + "?key=" + context["key"] + "&token=" + TOKEN,
        )

    # We use ai.imjoy.io to test the login for now
    token = await login(
        {
            "server_url": WS_SERVER_URL,
            "login_callback": callback,
            "login_timeout": 20,
        }
    )
    assert token == TOKEN


def test_login_sync(websocket_server):
    """Test login to the server."""
    TOKEN = "sf31df234"

    def callback(context):
        print(f"By passing login: {context['login_url']}")
        requests.get(
            context["report_url"] + "?key=" + context["key"] + "&token=" + TOKEN
        )

    # We use ai.imjoy.io to test the login for now
    token = login_sync(
        {
            "server_url": WS_SERVER_URL,
            "login_callback": callback,
            "login_timeout": 20,
        }
    )
    assert token == TOKEN


@pytest.mark.asyncio
async def test_numpy_array_sync(websocket_server):
    """Test numpy array registered in async."""
    ws = connect_to_server_sync(
        {"client_id": "test-plugin", "server_url": WS_SERVER_URL}
    )
    ws.export(ImJoyPlugin(ws))
    workspace = ws.config.workspace
    token = ws.generate_token()

    api = await connect_to_server(
        {
            "client_id": "client",
            "workspace": workspace,
            "token": token,
            "server_url": WS_SERVER_URL,
        }
    )
    plugin = await api.get_service("test-plugin:default")
    result = await plugin.add(2.1)
    assert result == 2.1 + 1.0

    large_array = np.zeros([2048, 2048, 4], dtype="float32")
    result = await plugin.add(large_array)
    np.testing.assert_array_equal(result, large_array + 1.0)


def test_connect_to_server_sync(websocket_server):
    """Test connecting to the server sync."""
    # Now all the functions are sync
    with connect_to_server_sync(
        {"client_id": "test-plugin", "server_url": WS_SERVER_URL}
    ) as server:
        workspace = server.config.workspace
        token = server.generate_token()
        assert workspace and token

        services = server.list_services("public")
        assert isinstance(services, list)

        def hello(name):
            print("Hello " + name)
            return "Hello " + name

        server.register_service(
            {
                "name": "Hello World",
                "id": "hello-world",
                "config": {
                    "visibility": "protected",
                    "run_in_executor": True,
                },
                "hello": hello,
            }
        )


def test_connect_to_server_sync(websocket_server):
    """Test connecting to the server sync."""
    # Now all the functions are sync
    with get_remote_service_sync(
        f"{WS_SERVER_URL}/public/services/hypha-login"
    ) as login:
        info = login.start()
        assert "key" in info


@pytest.mark.asyncio
async def test_export_api(websocket_server):
    """Test exporting API."""
    from hypha_rpc import api

    api.export({"hello": lambda x: "hello " + x}, {"name": "hello"})
    assert "hello" in api.get_registry()

    api.get_registry().clear()
    api.set_export_handler(lambda obj, config=None: None)
    api.export({"hello": lambda x: "hello " + x})
    assert "hello" not in api.get_registry().keys()

    api.get_registry().clear()
    api.set_export_handler(api._default_export_handler)
    api.export({"hello": lambda x: "hello " + x}, {"name": "hello2"})
    assert "hello2" in api.get_registry().keys()


@pytest.mark.asyncio
async def test_connect_to_server(websocket_server):
    """Test connecting to the server."""
    # test workspace is an exception, so it can pass directly
    ws = await connect_to_server({"name": "my plugin", "server_url": WS_SERVER_URL})
    with pytest.raises(Exception, match=r".*does not exist or is not accessible.*"):
        ws = await connect_to_server(
            {"name": "my plugin", "workspace": "test", "server_url": WS_SERVER_URL}
        )
    ws = await connect_to_server({"name": "my plugin", "server_url": WS_SERVER_URL})
    await ws.export(ImJoyPlugin(ws))

    def hello(name, key=12, context=None):
        """Say hello."""
        print("Hello " + name)
        return "Hello " + name

    await ws.register_service(
        {
            "name": "Hello World",
            "id": "hello-world",
            "description": "hello world service",
            "config": {
                "visibility": "protected",
                "run_in_executor": True,
            },
            "hello": hello,
        }
    )

    svc = await ws.get_service("hello-world")
    assert svc.hello.__doc__ == hello.__doc__
    assert svc.hello.__name__ == hello.__name__

    svc_info = await ws.register_service(
        {
            "name": "Hello World",
            "id": "hello-world",
            "description": "hello world service",
            "config": {
                "visibility": "protected",
                "run_in_executor": True,
                "require_context": True,
            },
            "hello": hello,
        },
        {"overwrite": True},
    )

    svc = await ws.get_service("hello-world")
    assert svc.hello.__doc__ == hello.__doc__
    assert svc.hello.__name__ == hello.__name__

    await ws.unregister_service(svc_info["id"])

    try:
        svc = await ws.get_service("hello-world")
    except Exception as e:
        assert "Service not found" in str(e)

    await ws.disconnect()


@pytest.mark.asyncio
async def test_numpy_transmission(websocket_server):
    """Test numpy array transmission."""
    api = await connect_to_server(
        {"name": "my app", "server_url": WS_SERVER_URL, "client_id": "my-app"}
    )
    image = np.random.rand(512, 512)
    embedding = await api.echo(image)
    assert isinstance(embedding, np.ndarray)
    assert embedding.shape == (512, 512)


@pytest.mark.asyncio
async def test_case_conversion(websocket_server):
    """Test case conversion."""
    ws = await connect_to_server(name="my plugin", server_url=WS_SERVER_URL)
    await ws.export(ImJoyPlugin(ws))

    def hello(name, key=12, context=None):
        """Say hello."""
        print("Hello " + name)
        return "Hello " + name

    info = await ws.register_service(
        {
            "name": "Hello World",
            "id": "hello-world",
            "description": "hello world service",
            "config": {
                "visibility": "protected",
                "run_in_executor": True,
            },
            "HelloWorld": hello,
        }
    )

    svc = await ws.get_service(info.id)
    assert await svc.HelloWorld("world") == "Hello world"

    svc = await ws.get_service(info.id, case_conversion="camel")
    assert await svc.helloWorld("world") == "Hello world"

    svc = await ws.get_service(info.id, case_conversion="snake")
    assert await svc.hello_world("world") == "Hello world"


@pytest.mark.asyncio
async def test_probe(websocket_server):
    """Test probes"""
    ws = await connect_to_server({"name": "my plugin", "server_url": WS_SERVER_URL})

    await ws.register_probes(
        {
            "readiness": lambda: True,
            "liveness": lambda: True,
        }
    )

    async with httpx.AsyncClient() as client:
        response = await client.get(
            f"{WS_SERVER_URL}/{ws.config.workspace}/services/probes/readiness"
        )
        response.raise_for_status()
        assert response.json() == True


@pytest.mark.asyncio
async def test_get_remote_service(websocket_server):
    """Test getting a remote service."""
    login = await get_remote_service(f"{WS_SERVER_URL}/public/services/hypha-login")
    info = await login.start()
    assert "key" in info

    async with get_remote_service(
        f"{WS_SERVER_URL}/public/services/hypha-login"
    ) as login:
        info = await login.start()
        assert "key" in info


@pytest.mark.asyncio
async def test_reconnect_to_server(websocket_server):
    """Test reconnecting to the server."""
    # test workspace is an exception, so it can pass directly
    ws = await connect_to_server({"name": "my plugin", "server_url": WS_SERVER_URL})
    await ws.register_service(
        {
            "name": "Hello World",
            "id": "hello-world",
            "description": "hello world service",
            "config": {
                "visibility": "protected",
                "run_in_executor": True,
            },
            "hello": lambda x: "hello " + x,
        }
    )
    # simulate abnormal close
    await ws.rpc._connection._websocket.close(1002)
    # will trigger reconnect
    svc = await ws.get_service("hello-world")
    assert await svc.hello("world") == "hello world"


@pytest.mark.asyncio
async def test_robust_reconnection_with_service_reregistration(websocket_server):
    """Test robust reconnection with exponential backoff and service re-registration."""
    import asyncio

    # Create connection with custom client ID for easier identification
    ws = await connect_to_server(
        {
            "name": "reconnection test plugin",
            "server_url": WS_SERVER_URL,
            "client_id": "reconnection-test-client",
        }
    )

    # Keep track of reconnection events
    reconnection_events = []
    service_registration_events = []

    def on_connected(info):
        reconnection_events.append({"type": "connected", "info": info})

    def on_services_registered(info):
        service_registration_events.append(
            {"type": "services_registered", "info": info}
        )

    def on_services_registration_failed(info):
        service_registration_events.append(
            {"type": "services_registration_failed", "info": info}
        )

    # Register event handlers
    ws.rpc.on("connected", on_connected)
    ws.rpc.on("services_registered", on_services_registered)
    ws.rpc.on("services_registration_failed", on_services_registration_failed)

    # Register multiple services to test batch re-registration
    service_data = {"counter": 0, "test_data": "initial"}

    await ws.register_service(
        {
            "name": "Counter Service",
            "id": "counter-service",
            "description": "Service with state for testing reconnection",
            "config": {"visibility": "protected"},
            "increment": lambda: service_data.update(
                {"counter": service_data["counter"] + 1}
            )
            or service_data["counter"],
            "get_counter": lambda: service_data["counter"],
            "set_data": lambda data: service_data.update({"test_data": data}),
            "get_data": lambda: service_data["test_data"],
        }
    )

    await ws.register_service(
        {
            "name": "Echo Service",
            "id": "echo-service",
            "description": "Simple echo service for testing",
            "config": {"visibility": "protected"},
            "echo": lambda x: f"echo: {x}",
            "reverse": lambda x: x[::-1] if isinstance(x, str) else str(x)[::-1],
        }
    )

    # Verify services work initially
    counter_svc = await ws.get_service("counter-service")
    echo_svc = await ws.get_service("echo-service")

    # Test initial functionality
    assert await counter_svc.get_counter() == 0
    assert await counter_svc.increment() == 1
    assert await echo_svc.echo("test") == "echo: test"
    assert await echo_svc.reverse("hello") == "olleh"

    # Clear events from initial connection
    reconnection_events.clear()
    service_registration_events.clear()

    # Simulate unexpected disconnection (code 1011 - unexpected condition)
    print("Simulating unexpected disconnection...")
    await ws.rpc._connection._websocket.close(1011)

    # Wait a moment for reconnection to complete
    # The new implementation should reconnect automatically
    await asyncio.sleep(2.0)

    # Verify services still work after reconnection
    print("Testing services after reconnection...")
    counter_svc = await ws.get_service("counter-service")
    echo_svc = await ws.get_service("echo-service")

    # Test that service state is preserved (since they were re-registered)
    current_counter = await counter_svc.get_counter()
    assert (
        current_counter == 1
    ), f"Counter should be 1 after reconnection, got {current_counter}"

    # Test incrementing works
    new_counter = await counter_svc.increment()
    assert new_counter == 2, f"Counter should be 2 after increment, got {new_counter}"

    # Test echo service still works
    echo_result = await echo_svc.echo("reconnected")
    assert echo_result == "echo: reconnected"

    reverse_result = await echo_svc.reverse("reconnected")
    assert reverse_result == "detcennocer"

    # Test setting new data
    await counter_svc.set_data("after_reconnection")
    data_result = await counter_svc.get_data()
    assert data_result == "after_reconnection"

    # Verify we got reconnection events
    assert len(reconnection_events) > 0, "Should have received reconnection events"

    # Verify we got service registration events
    assert (
        len(service_registration_events) > 0
    ), "Should have received service registration events"

    # Check if services were successfully re-registered
    successful_registration = any(
        event["type"] == "services_registered" and event["info"]["registered"] >= 2
        for event in service_registration_events
    )
    assert (
        successful_registration
    ), f"Services should have been re-registered successfully. Events: {service_registration_events}"

    print("✅ Robust reconnection with service re-registration test passed!")


@pytest.mark.asyncio
async def test_reconnection_exponential_backoff(websocket_server):
    """Test that reconnection uses exponential backoff."""
    import time

    ws = await connect_to_server(
        {
            "name": "backoff test plugin",
            "server_url": WS_SERVER_URL,
            "client_id": "backoff-test-client",
        }
    )

    # Register a simple service
    await ws.register_service(
        {
            "name": "Test Service",
            "id": "test-service",
            "config": {"visibility": "protected"},
            "test": lambda: "ok",
        }
    )

    # Record reconnection attempt times
    reconnection_times = []

    def on_connected(info):
        reconnection_times.append(time.time())

    ws.rpc.on("connected", on_connected)

    # Clear initial connection event
    reconnection_times.clear()

    # Simulate multiple disconnections to test backoff
    print("Testing exponential backoff behavior...")

    # First disconnection
    start_time = time.time()
    await ws.rpc._connection._websocket.close(1011)

    # Wait for reconnection
    await asyncio.sleep(3.0)

    # Should have reconnected by now
    assert len(reconnection_times) >= 1, "Should have reconnected at least once"

    # Test that service still works
    svc = await ws.get_service("test-service")
    result = await svc.test()
    assert result == "ok"

    print("✅ Exponential backoff test passed!")


@pytest.mark.asyncio
async def test_reconnection_cancellation(websocket_server):
    """Test that reconnection can be cancelled when explicitly disconnecting."""
    ws = await connect_to_server(
        {
            "name": "cancellation test plugin",
            "server_url": WS_SERVER_URL,
            "client_id": "cancellation-test-client",
        }
    )

    # Register a service
    await ws.register_service(
        {
            "name": "Test Service",
            "id": "test-service",
            "config": {"visibility": "protected"},
            "test": lambda: "ok",
        }
    )

    # Simulate unexpected disconnection
    await ws.rpc._connection._websocket.close(1011)

    # Give a moment for reconnection to start
    await asyncio.sleep(0.5)

    # Now explicitly disconnect - this should cancel reconnection
    await ws.disconnect()

    # Wait a bit more to ensure reconnection doesn't happen
    await asyncio.sleep(2.0)

    # Try to use the service - should fail
    try:
        svc = await ws.get_service("test-service")
        await svc.test()
        assert False, "Service should not be accessible after explicit disconnect"
    except Exception:
        # Expected - connection should be closed
        pass

    print("✅ Reconnection cancellation test passed!")


@pytest.mark.asyncio
async def test_numpy_array(websocket_server):
    """Test numpy array."""
    ws = await connect_to_server(
        {"client_id": "test-plugin", "server_url": WS_SERVER_URL}
    )
    await ws.export(ImJoyPlugin(ws))
    workspace = ws.config.workspace
    token = await ws.generate_token()

    api = await connect_to_server(
        {
            "client_id": "client",
            "workspace": workspace,
            "token": token,
            "server_url": WS_SERVER_URL,
        }
    )
    plugin = await api.get_service("test-plugin:default")
    result = await plugin.add(2.1)
    assert result == 2.1 + 1.0

    large_array = np.zeros([2048, 2048, 4], dtype="float32")
    result = await plugin.add(large_array)
    np.testing.assert_array_equal(result, large_array + 1.0)


@pytest.mark.asyncio
async def test_rtc_service(websocket_server):
    """Test RTC service."""
    from hypha_rpc import connect_to_server

    service_id = "test-rtc-service"
    server = await connect_to_server(
        {
            "server_url": WS_SERVER_URL,
        }
    )
    assert "get_service" in server and "getService" not in server
    assert "register_service" in server and "registerService" not in server
    await server.register_service(
        {
            "id": "echo-service",
            "config": {"visibility": "public"},
            "type": "echo",
            "echo": lambda x: x,
        }
    )
    svc = await register_rtc_service(server, service_id)
    pc = await get_rtc_service(server, svc["id"])
    svc = await pc.get_service("echo-service")
    assert await svc.echo("hello") == "hello", "echo service failed"
    await pc.close()


def test_rtc_service_sync(websocket_server):
    """Test RTC service."""
    from hypha_rpc import connect_to_server_sync

    service_id = "test-rtc-service"
    server = connect_to_server_sync(
        {
            "server_url": WS_SERVER_URL,
        }
    )
    server.register_service(
        {
            "id": "echo-service",
            "config": {"visibility": "public"},
            "type": "echo",
            "echo": lambda x: x,
        }
    )
    register_rtc_service_sync(server, service_id)
    pc = get_rtc_service_sync(server, service_id)
    svc = pc.get_service("echo-service")
    assert svc.echo("hello") == "hello", "echo service failed"
    pc.close()


def test_rtc_service_auto(websocket_server):
    """Test RTC service."""
    from hypha_rpc import connect_to_server_sync

    server = connect_to_server_sync(
        {
            "server_url": WS_SERVER_URL,
            "webrtc": True,
        }
    )
    server.register_service(
        {
            "id": "echo-service",
            "config": {"visibility": "public"},
            "type": "echo",
            "echo": lambda x: x,
        }
    )

    svc = server.get_service("echo-service")
    assert svc.echo("hello") == "hello", "echo service failed"


def test_connect_to_server_sync_lock(websocket_server):
    """Test connecting to the server sync with thread locking."""
    server = connect_to_server_sync(
        {"client_id": "test-plugin", "server_url": WS_SERVER_URL}
    )
    workspace = server.config.workspace
    token = server.generate_token()
    assert workspace and token

    services = server.list_services("public")
    assert isinstance(services, list)

    def hello(name):
        print("Hello " + name)
        return "Hello " + name

    def call_hello2():
        svc = server.get_service("hello-world-2")
        return svc.call_hello()

    server.register_service(
        {
            "name": "Hello World",
            "id": "hello-world",
            "config": {
                "visibility": "protected",
                "run_in_executor": True,
            },
            "hello": hello,
            "call_hello2": call_hello2,
        }
    )

    svc = server.get_service("hello-world")
    svc.hello("world")

    server2 = connect_to_server_sync(
        {
            "client_id": "test-plugin-2",
            "server_url": WS_SERVER_URL,
            "workspace": workspace,
            "token": token,
        }
    )

    def call_hello():
        svc = server2.get_service("hello-world")
        return svc.hello("world")

    server2.register_service(
        {
            "name": "Hello World 2",
            "id": "hello-world-2",
            "config": {
                "visibility": "protected",
                "run_in_executor": True,
            },
            "call_hello": call_hello,
        }
    )

    # This will not work if the thread is locked
    svc = server.get_service("hello-world")
    svc.call_hello2()


@pytest.mark.asyncio
async def test_generator(websocket_server):
    """Test using generators across RPC."""
    # Create a server with a service that returns a generator
    server = await connect_to_server(
        {"client_id": "generator-provider", "server_url": WS_SERVER_URL}
    )

    # Get server workspace and token for client connection
    workspace = server.config.workspace
    token = await server.generate_token()

    # Define a generator function
    def counter(start=0, end=5):
        """Return a generator that counts from start to end."""
        for i in range(start, end):
            yield i

    # Define an async generator function
    async def async_counter(start=0, end=5):
        """Return an async generator that counts from start to end."""
        for i in range(start, end):
            yield i
            await asyncio.sleep(0.01)  # Small delay to simulate async work

    # Register service with both types of generators
    await server.register_service(
        {
            "id": "generator-service",
            "config": {"visibility": "public"},
            "get_counter": counter,
            "get_async_counter": async_counter,
        }
    )

    # Connect with another client using the same workspace and token
    client = await connect_to_server(
        {
            "client_id": "generator-consumer",
            "server_url": WS_SERVER_URL,
            "workspace": workspace,
            "token": token,
        }
    )

    # Get the service
    gen_service = await client.get_service("generator-service")

    # Test normal generator - note that it becomes an async generator over RPC
    gen = await gen_service.get_counter(0, 5)
    results = []
    # We need to use async for since all generators become async generators over RPC
    async for item in gen:
        results.append(item)
    assert results == [0, 1, 2, 3, 4]

    # Test async generator
    async_gen = await gen_service.get_async_counter(0, 5)
    async_results = []
    async for item in async_gen:
        async_results.append(item)
    assert async_results == [0, 1, 2, 3, 4]


def test_generator_sync(websocket_server):
    """Test using generators with the synchronous API."""
    # Create a server with a service that returns a generator
    server = connect_to_server_sync(
        {"client_id": "sync-generator-provider", "server_url": WS_SERVER_URL}
    )

    # Get server workspace and token for client connection
    workspace = server.config.workspace
    token = server.generate_token()

    # Define a generator function
    def counter(start=0, end=5):
        """Return a generator that counts from start to end."""
        for i in range(start, end):
            yield i

    # Define an async generator function
    async def async_counter(start=0, end=5):
        """Return an async generator that counts from start to end."""
        for i in range(start, end):
            yield i
            await asyncio.sleep(0.01)  # Small delay to simulate async work

    # Register service with both types of generators
    svc_info = server.register_service(
        {
            "id": "sync-generator-service",
            "config": {"visibility": "public"},
            "get_counter": counter,
            "get_async_counter": async_counter,
        }
    )

    # Connect with another client using the same workspace and token
    client = connect_to_server_sync(
        {
            "client_id": "sync-generator-consumer",
            "server_url": WS_SERVER_URL,
            "workspace": workspace,
            "token": token,
        }
    )

    # Get service with explicit timeout
    gen_service = client.get_service(svc_info["id"], timeout=20)

    # Test normal generator - verify it works as a synchronous generator
    gen = gen_service.get_counter(0, 5)
    results = []
    for item in gen:
        results.append(item)
    assert results == [0, 1, 2, 3, 4]

    # Test async generator - should also work with the sync API
    gen = gen_service.get_async_counter(0, 3)
    results = []
    for item in gen:
        results.append(item)
    assert results == [0, 1, 2]


@pytest.mark.asyncio
@pytest.mark.skipif(not HAS_PYDANTIC, reason="Pydantic is not installed")
async def test_pydantic_codec(websocket_server):
    """Test Pydantic model encoding and decoding via RPC."""
    server = await connect_to_server(
        {"client_id": "pydantic-provider", "server_url": WS_SERVER_URL}
    )
    workspace = server.config.workspace
    token = await server.generate_token()

    # Register the Pydantic codec
    register_pydantic_codec(server.rpc)

    # Define a service that echoes Pydantic models
    async def echo_model(model: TestModel) -> TestModel:
        return model

    await server.register_service(
        {
            "id": "pydantic-echo-service",
            "config": {"visibility": "public"},
            "echo_model": echo_model,
        }
    )

    # Connect a client
    client = await connect_to_server(
        {
            "client_id": "pydantic-consumer",
            "server_url": WS_SERVER_URL,
            "workspace": workspace,
            "token": token,
        }
    )
    # Also register the codec on the client side for decoding the response
    register_pydantic_codec(client.rpc)

    # Get the service
    echo_svc = await client.get_service("pydantic-echo-service")

    # Create a model instance
    original_model = TestModel(name="test", value=123, tags=["a", "b"])

    # Call the service
    returned_model = await echo_svc.echo_model(original_model)

    # Assertions
    assert issubclass(returned_model.__class__, BaseModel)
    assert returned_model.name == "test"
    assert returned_model.value == 123
    assert returned_model.is_active is True
    assert returned_model.tags == ["a", "b"]
    # assert returned_model == original_model # This fails because the classes are technically different

    await server.disconnect()
    await client.disconnect()


@pytest.mark.asyncio
async def test_schema_annotation_python(websocket_server):
    """Test schema generation from type hints and Pydantic models."""
    server = await connect_to_server(
        {"client_id": "schema-provider-py", "server_url": WS_SERVER_URL}
    )

    # Register the service with functions decorated by schema_function
    functions_to_register = {
        "add_numbers": add_numbers,
    }
    if HAS_PYDANTIC:
        functions_to_register["process_test_data"] = process_test_data

    service_info = await server.register_service(
        {
            "id": "schema-test-py-service",
            "config": {"visibility": "public"},
            **functions_to_register,
        }
    )

    assert "service_schema" in service_info
    service_schema = service_info["service_schema"]

    # --- Debugging ---
    print(f"DEBUG: service_schema keys = {list(service_schema.keys())}")
    # --- End Debugging ---

    # Verify schema for add_numbers
    assert "add_numbers" in service_schema
    add_schema = service_schema["add_numbers"]
    assert add_schema["type"] == "function"
    assert add_schema["function"]["name"] == "add_numbers"
    assert (
        add_schema["function"]["description"]
        == "Adds two numbers, an integer and a float."
    )
    assert add_schema["function"]["parameters"]["type"] == "object"
    assert "a" in add_schema["function"]["parameters"]["properties"]
    assert add_schema["function"]["parameters"]["properties"]["a"]["type"] == "integer"
    assert "b" in add_schema["function"]["parameters"]["properties"]
    assert add_schema["function"]["parameters"]["properties"]["b"]["type"] == "number"
    assert add_schema["function"]["parameters"]["properties"]["b"]["default"] == 3.14
    assert add_schema["function"]["parameters"]["required"] == ["a"]

    # Verify schema for process_test_data if Pydantic is available
    if HAS_PYDANTIC:
        assert "process_test_data" in service_schema
        process_schema = service_schema["process_test_data"]
        assert process_schema["type"] == "function"
        assert process_schema["function"]["name"] == "process_test_data"
        assert (
            process_schema["function"]["description"]
            == "Processes the provided test data."
        )
        assert process_schema["function"]["parameters"]["type"] == "object"
        assert "data" in process_schema["function"]["parameters"]["properties"]
        data_param_schema = process_schema["function"]["parameters"]["properties"][
            "data"
        ]
        # Verify that the registered schema uses $ref for the Pydantic model
        assert "$ref" in data_param_schema
        assert (
            data_param_schema["$ref"] == "#/$defs/TestData"
            or data_param_schema["$ref"] == "#/definitions/TestData"
        )

        # Now, verify the *local* schema generated by the decorator
        local_schema = process_test_data.__schema__
        # assert "function" in local_schema # Local schema doesn't have this wrapper
        # local_func_schema = local_schema["function"]
        defs_key = "$defs" if "$defs" in local_schema["parameters"] else "definitions"
        assert defs_key in local_schema["parameters"]
        assert "TestData" in local_schema["parameters"][defs_key]
        model_schema = local_schema["parameters"][defs_key]["TestData"]
        assert model_schema["type"] == "object"
        assert "item_id" in model_schema["properties"]
        assert model_schema["properties"]["item_id"]["type"] == "integer"
        assert (
            model_schema["properties"]["item_id"]["description"] == "The ID of the item"
        )
        assert "name" in model_schema["properties"]
        assert model_schema["properties"]["name"]["type"] == "string"
        assert "price" in model_schema["properties"]
        assert model_schema["properties"]["price"]["type"] == "number"
        assert "is_offer" in model_schema["properties"]
        assert (
            model_schema["properties"]["is_offer"]["description"]
            == "Whether this is an offer"
        )
        is_offer_schema = model_schema["properties"]["is_offer"]
        # Compatibility check for Optional[bool] in Pydantic v1/v2
        is_optional_bool = False
        if "anyOf" in is_offer_schema:
            is_optional_bool = any(
                t.get("type") == "boolean" for t in is_offer_schema["anyOf"]
            ) and any(t.get("type") == "null" for t in is_offer_schema["anyOf"])
        elif "type" in is_offer_schema:
            # Pydantic v1 might represent Optional[bool] as type: ["boolean", "null"]
            is_optional_bool = (
                isinstance(is_offer_schema["type"], list)
                and "boolean" in is_offer_schema["type"]
                and "null" in is_offer_schema["type"]
            )
        assert (
            is_optional_bool
        ), f"Schema for is_offer is not Optional[bool]: {is_offer_schema}"

        assert "item_id" in model_schema.get("required", [])
        assert "name" in model_schema.get("required", [])
        assert "price" in model_schema.get("required", [])
        assert process_schema["function"]["parameters"]["required"] == ["data"]

    # Optional: Test calling the functions via RPC
    client = await connect_to_server(
        {
            "client_id": "schema-consumer-py",
            "server_url": WS_SERVER_URL,
            "workspace": server.config.workspace,  # Explicitly set workspace
            "token": await server.generate_token(),  # Generate token for the workspace
        }
    )
    svc = await client.get_service("schema-test-py-service")
    assert await svc.add_numbers(5, b=2.5) == 7.5
    if HAS_PYDANTIC:
        # Verify the local schema generated by the decorator before registration -- MOVED THIS BLOCK UP
        # Test the RPC call
        result = await svc.process_test_data(
            {
                "item_id": 101,
                "name": "Test Item",
                "price": 99.99,
                "is_offer": True,
            }
        )
        assert result == "Processed Test Item with price 99.99"

    await server.disconnect()
    await client.disconnect()


@pytest.mark.asyncio
async def test_service_recovery_after_disconnection(websocket_server):
    """Test that disconnection is handled gracefully without crashes."""
    # Create a connection to the server
    print("\n=== TEST DISCONNECTION HANDLING ===")
    ws = await connect_to_server(
        {"name": "disconnect-test", "server_url": WS_SERVER_URL}
    )

    # Register a service with a simple method
    test_data = {"counter": 0}

    print("Registering test service...")
    service_info = await ws.register_service(
        {
            "name": "Disconnect Test Service",
            "id": "disconnect-service",
            "description": "Service to test disconnection handling",
            "config": {
                "visibility": "protected",
                "run_in_executor": True,
            },
            "increment": lambda: test_data.update({"counter": test_data["counter"] + 1})
            or test_data["counter"],
            "get_counter": lambda: test_data["counter"],
        }
    )

    # Verify the ID format to make sure it's properly registered
    assert (
        "/" in service_info["id"] and ":" in service_info["id"]
    ), "Service ID should be absolute"
    print(f"Service registered with ID: {service_info['id']}")

    # Verify the service works initially
    svc = await ws.get_service("disconnect-service")
    print("Testing service before disconnection:")
    print(f"Counter value: {await svc.get_counter()}")
    print(f"Incrementing: {await svc.increment()}")

    # Verify it incremented correctly
    counter_value = await svc.get_counter()
    assert counter_value == 1, f"Counter should be 1, got {counter_value}"

    # Test graceful disconnection handling
    print("\n=== TESTING DISCONNECTION HANDLING ===")
    print("Simulating network disconnection...")

    # Close the connection to simulate network issues
    if hasattr(ws.rpc._connection, "_websocket") and ws.rpc._connection._websocket:
        await ws.rpc._connection._websocket.close(code=1000)  # Normal closure

    # Give time for the disconnection to be processed
    await asyncio.sleep(2)

    # Test that operations fail gracefully after disconnection
    print("Testing operations after disconnection...")
    try:
        await svc.get_counter()
        print(
            "WARNING: Operation succeeded after disconnection - this might indicate connection recovery"
        )
    except Exception as e:
        print(f"Expected: Operation failed after disconnection: {type(e).__name__}")

    # Test that we can create a new connection
    print("\n=== TESTING NEW CONNECTION AFTER DISCONNECTION ===")
    ws_new = await connect_to_server(
        {"name": "new-connection-test", "server_url": WS_SERVER_URL}
    )

    # Register a new service to verify the new connection works
    new_service_info = await ws_new.register_service(
        {
            "name": "New Connection Test Service",
            "id": "new-connection-service",
            "description": "Service to test new connection after disconnection",
            "config": {"visibility": "protected"},
            "test": lambda: "new connection works",
        }
    )

    print(f"New service registered with ID: {new_service_info['id']}")

    # Test the new service
    new_svc = await ws_new.get_service("new-connection-service")
    result = await new_svc.test()
    assert (
        result == "new connection works"
    ), f"Expected 'new connection works', got {result}"

    print("✅ New connection and service registration works correctly")

    print("\n=== DISCONNECTION HANDLING TEST COMPLETED SUCCESSFULLY! ===")

    # Clean up
    try:
        await ws.disconnect()
    except Exception as e:
        print(f"Note: Error disconnecting original ws (expected): {e}")

    try:
        await ws_new.disconnect()
    except Exception as e:
        print(f"Error disconnecting new ws: {e}")


@pytest.mark.asyncio
async def test_memory_leak_prevention(websocket_server):
    """Comprehensive test suite for memory leak prevention."""
    from hypha_rpc import connect_to_server
    import gc
    import sys
    import tracemalloc

    # Start memory tracing
    tracemalloc.start()

    # Connect to server
    api = await connect_to_server(
        {
            "client_id": "memory-leak-test-client",
            "server_url": WS_SERVER_URL,
        }
    )

    def get_detailed_session_analysis(rpc):
        """Comprehensive session analysis."""
        analysis = {
            "total_sessions": 0,
            "session_details": [],
            "system_stores": {},
            "memory_usage": 0
        }

        if hasattr(rpc, "_object_store"):
            store = rpc._object_store
            for key, value in store.items():
                if key in ["services", "message_cache"]:
                    analysis["system_stores"][key] = {
                        "type": str(type(value)),
                        "size": len(value) if hasattr(value, "__len__") else "unknown"
                    }
                else:
                    # This is a session
                    analysis["total_sessions"] += 1
                    session_info = {
                        "id": key,
                        "type": "dict" if isinstance(value, dict) else str(type(value)),
                        "has_promise_manager": isinstance(value, dict) and "_promise_manager" in value,
                        "has_timer": isinstance(value, dict) and "timer" in value,
                        "has_heartbeat": isinstance(value, dict) and "heartbeat_task" in value,
                        "nested_items": len(value) if isinstance(value, dict) else 0
                    }
                    analysis["session_details"].append(session_info)

        # Get memory usage
        current, peak = tracemalloc.get_traced_memory()
        analysis["memory_usage"] = current

        return analysis

    def assert_clean_state(analysis, test_name, initial_analysis=None):
        """Assert that the RPC is in a clean state."""
        print(f"\n--- {test_name} Analysis ---")
        print(f"Total sessions: {analysis['total_sessions']}")
        print(f"Memory usage: {analysis['memory_usage']:,} bytes")
        
        if analysis["session_details"]:
            print("Session details:")
            for session in analysis["session_details"]:
                print(f"  - {session['id']}: {session}")
        
        # Should have no sessions after operations complete
        assert analysis["total_sessions"] == 0, f"Memory leak detected: {analysis['total_sessions']} sessions remaining after {test_name}"
        
        # Message cache should be empty
        if "message_cache" in analysis["system_stores"]:
            assert analysis["system_stores"]["message_cache"]["size"] == 0, "Message cache not clean"

        # Memory usage should not grow excessively
        if initial_analysis:
            growth = analysis["memory_usage"] - initial_analysis["memory_usage"]
            growth_mb = growth / (1024 * 1024)
            print(f"Memory growth: {growth_mb:.2f} MB")
            # Allow some growth but flag excessive leaks (>10MB would be concerning for these tests)
            assert growth_mb < 10, f"Excessive memory growth: {growth_mb:.2f} MB"

    # Test 1: Baseline state
    print("=== COMPREHENSIVE MEMORY LEAK TESTS ===")
    initial_analysis = get_detailed_session_analysis(api.rpc)
    assert_clean_state(initial_analysis, "Initial State")

    # Test 2: Simple operations
    print("\n=== Test 2: Simple Operations ===")
    result = await api.echo("simple_test")
    assert result == "simple_test"
    
    services = await api.list_services()
    assert isinstance(services, list)
    
    # Allow time for cleanup
    await asyncio.sleep(0.3)
    gc.collect()  # Force garbage collection
    
    simple_analysis = get_detailed_session_analysis(api.rpc)
    assert_clean_state(simple_analysis, "Simple Operations", initial_analysis)

    # Test 3: Concurrent operations stress test
    print("\n=== Test 3: Concurrent Operations Stress Test ===")
    tasks = []
    for i in range(20):  # Increased from 3 to 20 for stress testing
        tasks.extend([
            api.echo(f"concurrent_test_{i}_a"),
            api.echo(f"concurrent_test_{i}_b"),
            api.list_services() if i % 5 == 0 else api.echo(f"concurrent_test_{i}_c")
        ])
    
    results = await asyncio.gather(*tasks)
    assert len(results) == len(tasks)
    
    await asyncio.sleep(0.5)  # More time for cleanup of many sessions
    gc.collect()
    
    concurrent_analysis = get_detailed_session_analysis(api.rpc)
    assert_clean_state(concurrent_analysis, "Concurrent Operations", initial_analysis)

    # Test 4: Exception handling - operations that might fail
    print("\n=== Test 4: Exception Handling ===")
    exception_count = 0
    for i in range(5):
        try:
            # Try to get a non-existent service (should fail)
            await api.get_service(f"non_existent_service_{i}")
        except Exception:
            exception_count += 1
            pass  # Expected to fail
    
    assert exception_count > 0, "Expected some exceptions for non-existent services"
    
    await asyncio.sleep(0.3)
    gc.collect()
    
    exception_analysis = get_detailed_session_analysis(api.rpc)
    assert_clean_state(exception_analysis, "Exception Handling", initial_analysis)

    # Test 5: Large data operations
    print("\n=== Test 5: Large Data Operations ===")
    large_data = "x" * 10000  # 10KB string
    for i in range(5):
        result = await api.echo(large_data)
        assert len(result) == len(large_data)
    
    await asyncio.sleep(0.3)
    gc.collect()
    
    large_data_analysis = get_detailed_session_analysis(api.rpc)
    assert_clean_state(large_data_analysis, "Large Data Operations", initial_analysis)

    # Test 6: Rapid sequential operations
    print("\n=== Test 6: Rapid Sequential Operations ===")
    for i in range(50):  # Many rapid operations
        result = await api.echo(f"rapid_{i}")
        assert result == f"rapid_{i}"
    
    await asyncio.sleep(0.5)
    gc.collect()
    
    rapid_analysis = get_detailed_session_analysis(api.rpc)
    assert_clean_state(rapid_analysis, "Rapid Sequential Operations", initial_analysis)

    # Test 7: Mixed operation types
    print("\n=== Test 7: Mixed Operation Types ===")
    mixed_tasks = []
    for i in range(10):
        mixed_tasks.extend([
            api.echo(f"mixed_{i}"),
            api.list_services(),
            api.get_client_info() if hasattr(api, 'get_client_info') else api.echo(f"info_{i}")
        ])
    
    mixed_results = await asyncio.gather(*mixed_tasks, return_exceptions=True)
    # Some might be exceptions (like get_client_info if not available), that's ok
    
    await asyncio.sleep(0.5)
    gc.collect()
    
    mixed_analysis = get_detailed_session_analysis(api.rpc)
    assert_clean_state(mixed_analysis, "Mixed Operation Types", initial_analysis)

    # Test 8: Service registration and cleanup (more lenient)
    print("\n=== Test 8: Service Registration and Cleanup ===")
    pre_service_analysis = get_detailed_session_analysis(api.rpc)
    
    test_services = []
    for i in range(3):
        service_info = await api.register_service({
            "id": f"temp_service_{i}",
            "config": {"visibility": "protected"},
            "test_method": lambda x: f"test_{x}",
        })
        test_services.append(service_info["id"])
    
    # Use the services
    for service_id in test_services:
        try:
            svc = await api.get_service(service_id.split(":")[-1])  # Get local part
            result = await svc.test_method("hello")
            assert "test_" in result
        except Exception as e:
            print(f"Service test failed (might be expected): {e}")
    
    # Unregister services
    for service_id in test_services:
        try:
            await api.unregister_service(service_id.split(":")[-1])
        except Exception as e:
            print(f"Unregister failed (might be expected): {e}")
    
    await asyncio.sleep(0.5)  # Extra time for service cleanup
    gc.collect()
    
    service_analysis = get_detailed_session_analysis(api.rpc)
    print(f"\n--- Service Registration Analysis ---")
    print(f"Total sessions: {service_analysis['total_sessions']}")
    print(f"Pre-service sessions: {pre_service_analysis['total_sessions']}")
    
    if service_analysis["session_details"]:
        print("Remaining sessions after service operations:")
        for session in service_analysis["session_details"]:
            print(f"  - {session['id']}: {session}")
    
    # Service registration may create some legitimate persistent sessions
    # We check that we don't have excessive growth (>10 sessions would be concerning)
    session_growth = service_analysis['total_sessions'] - pre_service_analysis['total_sessions']
    assert session_growth <= 10, f"Excessive session growth from service operations: {session_growth} sessions"
    
    # Memory usage should not grow excessively
    if initial_analysis:
        growth = service_analysis["memory_usage"] - initial_analysis["memory_usage"]
        growth_mb = growth / (1024 * 1024)
        print(f"Memory growth: {growth_mb:.2f} MB")
        assert growth_mb < 10, f"Excessive memory growth: {growth_mb:.2f} MB"
    
    print("✅ Service registration cleanup within acceptable limits")

    # Final comprehensive check
    print("\n=== Final Comprehensive Analysis ===")
    final_analysis = get_detailed_session_analysis(api.rpc)
    
    print(f"\n--- Final State Analysis ---")
    print(f"Total sessions: {final_analysis['total_sessions']}")
    print(f"Expected sessions (from services): {service_analysis['total_sessions']}")
    print(f"Memory usage: {final_analysis['memory_usage']:,} bytes")
    
    if final_analysis["session_details"]:
        print("Final session details:")
        for session in final_analysis["session_details"]:
            print(f"  - {session['id']}: {session}")
    
    # Final state should not have more sessions than after service registration
    assert final_analysis["total_sessions"] <= service_analysis["total_sessions"], \
        f"Session increase after service registration: {final_analysis['total_sessions']} > {service_analysis['total_sessions']}"
    
    # Memory should not grow excessively from service registration state
    memory_growth = final_analysis["memory_usage"] - service_analysis["memory_usage"]
    memory_growth_mb = memory_growth / (1024 * 1024)
    print(f"Memory growth since service test: {memory_growth_mb:.2f} MB")
    assert memory_growth_mb < 1, f"Excessive memory growth since service test: {memory_growth_mb:.2f} MB"

    # Clean disconnect
    await api.disconnect()
    
    # Stop memory tracing
    tracemalloc.stop()

    print("✅ ALL MEMORY LEAK TESTS PASSED - No memory leaks detected!")


@pytest.mark.asyncio
async def test_memory_leak_edge_cases(websocket_server):
    """Test memory leak prevention in edge cases and error conditions."""
    from hypha_rpc import connect_to_server
    import gc

    api = await connect_to_server({
        "client_id": "edge-case-test-client", 
        "server_url": WS_SERVER_URL,
    })

    def get_session_count(rpc):
        """Get current session count."""
        if not hasattr(rpc, "_object_store"):
            return 0
        return len([k for k in rpc._object_store.keys() if k not in ["services", "message_cache"]])

    initial_count = get_session_count(api.rpc)
    print(f"Initial session count: {initial_count}")

    # Test 1: Timeout scenarios (if API supports timeouts)
    print("\n=== Edge Case 1: Operations with Different Patterns ===")
    
    # Test with empty strings, None-like values, special characters
    test_values = ["", "null", "undefined", "{}[]();", "🚀🔥💻", "\n\t\r", "  ", None]
    
    for i, value in enumerate(test_values):
        try:
            if value is not None:
                result = await api.echo(value)
                assert result == value
            else:
                # Skip None as it might not be JSON serializable
                continue
        except Exception as e:
            print(f"Expected potential failure for value {i}: {e}")
    
    await asyncio.sleep(0.2)
    gc.collect()
    
    edge_count_1 = get_session_count(api.rpc)
    assert edge_count_1 <= initial_count, f"Sessions leaked in edge case 1: {edge_count_1} > {initial_count}"

    # Test 2: Rapid connection/disconnection patterns (simulated)
    print("\n=== Edge Case 2: Rapid Operations ===")
    
    # Simulate rapid operations that might be cancelled
    tasks = []
    for i in range(100):  # Many rapid tasks
        tasks.append(api.echo(f"rapid_edge_{i}"))
        if i % 10 == 0:  # Add some list_services calls
            tasks.append(api.list_services())
    
    # Execute all at once - this might create many sessions simultaneously
    results = await asyncio.gather(*tasks)
    
    # Check results
    successful = sum(1 for r in results if not isinstance(r, Exception))
    failed = len(results) - successful
    print(f"Rapid operations: {successful} successful, {failed} failed")
    
    await asyncio.sleep(0.5)  # Give extra time for cleanup
    gc.collect()
    
    edge_count_2 = get_session_count(api.rpc)
    assert edge_count_2 <= initial_count, f"Sessions leaked in rapid operations: {edge_count_2} > {initial_count}"

    # Test 3: Mixed success/failure scenarios
    print("\n=== Edge Case 3: Mixed Success/Failure ===")
    
    mixed_operations = []
    for i in range(20):
        # Mix of valid and invalid operations
        mixed_operations.append(api.echo(f"valid_{i}"))
        
        # Try invalid operations that should fail
        try:
            mixed_operations.append(api.get_service(f"invalid_service_{i}"))
        except:
            pass  # Expected to fail during creation
    
    # Execute with exception handling
    mixed_results = await asyncio.gather(*mixed_operations, return_exceptions=True)
    
    exceptions = sum(1 for r in mixed_results if isinstance(r, Exception))
    successes = len(mixed_results) - exceptions
    print(f"Mixed operations: {successes} successful, {exceptions} exceptions")
    
    await asyncio.sleep(0.3)
    gc.collect()
    
    edge_count_3 = get_session_count(api.rpc)
    assert edge_count_3 <= initial_count, f"Sessions leaked in mixed operations: {edge_count_3} > {initial_count}"

    # Final verification
    final_count = get_session_count(api.rpc)
    print(f"Final session count: {final_count}")
    assert final_count <= initial_count, f"Overall session leak detected: {final_count} > {initial_count}"

    await api.disconnect()
    print("✅ EDGE CASE MEMORY TESTS PASSED")


@pytest.mark.asyncio 
async def test_session_cleanup_robustness(websocket_server):
    """Test the robustness of session cleanup mechanisms."""
    from hypha_rpc import connect_to_server
    import gc

    api = await connect_to_server({
        "client_id": "cleanup-robustness-test",
        "server_url": WS_SERVER_URL,
    })

    def analyze_object_store(rpc):
        """Detailed analysis of object store contents."""
        if not hasattr(rpc, "_object_store"):
            return {"sessions": 0, "details": "No object store"}
        
        store = rpc._object_store
        sessions = []
        system_stores = {}
        
        for key, value in store.items():
            if key in ["services", "message_cache"]:
                system_stores[key] = {
                    "size": len(value) if hasattr(value, "__len__") else "unknown",
                    "type": str(type(value))
                }
            else:
                sessions.append({
                    "id": key,
                    "type": str(type(value)),
                    "is_dict": isinstance(value, dict),
                    "size": len(value) if hasattr(value, "__len__") else "unknown"
                })
        
        return {
            "sessions": len(sessions),
            "session_details": sessions,
            "system_stores": system_stores
        }

    print("=== SESSION CLEANUP ROBUSTNESS TESTS ===")
    
    initial_analysis = analyze_object_store(api.rpc)
    print(f"Initial state: {initial_analysis['sessions']} sessions")
    
    # Test 1: Verify cleanup works under normal conditions
    print("\n--- Test 1: Normal Operation Cleanup ---")
    for i in range(10):
        result = await api.echo(f"normal_{i}")
        assert result == f"normal_{i}"
    
    await asyncio.sleep(0.2)
    gc.collect()
    
    normal_analysis = analyze_object_store(api.rpc)
    print(f"After normal operations: {normal_analysis['sessions']} sessions")
    assert normal_analysis["sessions"] == 0, f"Normal operations left {normal_analysis['sessions']} sessions"

    # Test 2: Concurrent session creation and cleanup
    print("\n--- Test 2: Concurrent Session Management ---")
    
    # Create many concurrent operations to stress the session management
    batch_size = 50
    batches = 3
    
    for batch in range(batches):
        print(f"  Batch {batch + 1}/{batches}")
        tasks = [api.echo(f"concurrent_batch_{batch}_{i}") for i in range(batch_size)]
        results = await asyncio.gather(*tasks)
        assert len(results) == batch_size
        
        # Brief pause between batches
        await asyncio.sleep(0.1)
    
    await asyncio.sleep(0.5)  # Extra time for cleanup
    gc.collect()
    
    concurrent_analysis = analyze_object_store(api.rpc)
    print(f"After concurrent operations: {concurrent_analysis['sessions']} sessions")
    assert concurrent_analysis["sessions"] == 0, f"Concurrent operations left {concurrent_analysis['sessions']} sessions"

    # Test 3: Stress test with rapid creation/cleanup cycles
    print("\n--- Test 3: Rapid Creation/Cleanup Cycles ---")
    
    for cycle in range(5):
        # Create burst of operations
        burst_tasks = [api.echo(f"burst_{cycle}_{i}") for i in range(20)]
        await asyncio.gather(*burst_tasks)
        
        # Force cleanup opportunity
        await asyncio.sleep(0.1)
        gc.collect()
        
        # Check intermediate state
        intermediate_analysis = analyze_object_store(api.rpc)
        if intermediate_analysis["sessions"] > 0:
            print(f"  Cycle {cycle}: {intermediate_analysis['sessions']} sessions (transient)")
    
    # Final cleanup
    await asyncio.sleep(0.3)
    gc.collect()
    
    cycles_analysis = analyze_object_store(api.rpc)
    print(f"After rapid cycles: {cycles_analysis['sessions']} sessions")
    assert cycles_analysis["sessions"] == 0, f"Rapid cycles left {cycles_analysis['sessions']} sessions"

    # Test 4: Large payload cleanup
    print("\n--- Test 4: Large Payload Cleanup ---")
    
    large_payloads = ["x" * (1024 * i) for i in range(1, 6)]  # 1KB to 5KB
    for i, payload in enumerate(large_payloads):
        result = await api.echo(payload)
        assert len(result) == len(payload)
        print(f"  Large payload {i+1}: {len(payload)} bytes processed")
    
    await asyncio.sleep(0.3)
    gc.collect()
    
    large_analysis = analyze_object_store(api.rpc)
    print(f"After large payloads: {large_analysis['sessions']} sessions")
    assert large_analysis["sessions"] == 0, f"Large payloads left {large_analysis['sessions']} sessions"

    # Final comprehensive check
    print("\n--- Final Robustness Verification ---")
    final_analysis = analyze_object_store(api.rpc)
    
    print("Final object store analysis:")
    print(f"  Sessions: {final_analysis['sessions']}")
    print(f"  System stores: {final_analysis['system_stores']}")
    
    if final_analysis["session_details"]:
        print("  Remaining sessions:")
        for session in final_analysis["session_details"]:
            print(f"    - {session}")
    
    assert final_analysis["sessions"] == 0, "Session cleanup robustness test failed - sessions remain"
    
    # Verify message cache is clean
    if "message_cache" in final_analysis["system_stores"]:
        cache_size = final_analysis["system_stores"]["message_cache"]["size"]
        assert cache_size == 0, f"Message cache not clean: {cache_size} items"

    await api.disconnect()
    print("✅ SESSION CLEANUP ROBUSTNESS TESTS PASSED")


@pytest.mark.asyncio
async def test_comprehensive_reconnection_scenarios(restartable_server):
    """Test comprehensive reconnection scenarios including server restarts - with timeouts."""
    print("\n=== COMPREHENSIVE RECONNECTION TEST ===")
    
    try:
        # Create connection with timeout
        ws = await asyncio.wait_for(
            connect_to_server({
                "name": "reconnection-test-client",
                "server_url": f"ws://127.0.0.1:{restartable_server.port}/ws",
                "client_id": "reconnection-test"
            }),
            timeout=10.0
        )
        
        # Track events for verification
        reconnection_events = []
        service_events = []
        
        def on_connected(info):
            reconnection_events.append({"type": "connected", "time": time.time(), "info": info})
            print(f"📡 Connected: {info.get('workspace', 'N/A')}")
        
        def on_services_registered(info):
            service_events.append({"type": "registered", "time": time.time(), "count": info.get("registered", 0)})
            print(f"🔧 Services registered: {info.get('registered', 0)}")
        
        ws.rpc.on("connected", on_connected)
        ws.rpc.on("services_registered", on_services_registered)
        
        # Register test services with state
        test_state = {"counter": 0, "data": "initial"}
        
        service_info = await asyncio.wait_for(
            ws.register_service({
                "id": "persistent-service",
                "name": "Persistent Test Service",
                "config": {"visibility": "protected"},
                "get_counter": lambda: test_state["counter"],
                "increment": lambda: test_state.update({"counter": test_state["counter"] + 1}) or test_state["counter"],
                "set_data": lambda data: test_state.update({"data": data}) or "ok",
                "get_data": lambda: test_state["data"],
                "ping": lambda: "pong"
            }),
            timeout=5.0
        )
        
        print(f"🏷️  Service registered: {service_info['id']}")
        
        # Test initial functionality
        svc = await ws.get_service("persistent-service")
        assert await svc.ping() == "pong"
        assert await svc.get_counter() == 0
        await svc.increment()
        assert await svc.get_counter() == 1
        await svc.set_data("pre-restart")
        assert await svc.get_data() == "pre-restart"
        
        print("✅ Initial service functionality verified")
        
        # Clear initial events
        reconnection_events.clear()
        service_events.clear()
        
        # Test 1: Clean server restart (simulates k8s upgrade)
        print("\n--- TEST 1: Clean Server Restart ---")
        print("🔄 Restarting server cleanly...")
        restartable_server.restart(stop_delay=0.5)
        
        # Wait for reconnection with timeout
        await asyncio.wait_for(_wait_for_service_recovery(ws, "persistent-service", "post-restart-1"), timeout=15.0)
        print("✅ Clean restart reconnection successful")
        
        # Test 2: Abrupt connection closure
        print("\n--- TEST 2: Abrupt Connection Closure ---")
        print("💥 Closing connection abruptly...")
        await ws.rpc._connection._websocket.close(1011)  # Unexpected condition
        
        await asyncio.wait_for(_wait_for_service_recovery(ws, "persistent-service", "post-abrupt-close"), timeout=10.0)
        print("✅ Abrupt closure reconnection successful")
        
        # Test 3: Multiple rapid disconnections (simplified)
        print("\n--- TEST 3: Multiple Rapid Disconnections ---")
        valid_codes = [1000, 1001]  # Use only valid close codes
        for i, code in enumerate(valid_codes):
            print(f"🔄 Rapid disconnect #{i+1} (code {code})")
            await ws.rpc._connection._websocket.close(code)
            await asyncio.sleep(1.0)  # Increased wait time
        
        # Wait for final reconnection
        await asyncio.wait_for(_wait_for_service_recovery(ws, "persistent-service", "final-test"), timeout=10.0)
        print("✅ Multiple rapid disconnections handled")
        
        # Verify reconnection events occurred
        print(f"\n📈 Reconnection events: {len(reconnection_events)}")
        
        # Final verification
        svc = await ws.get_service("persistent-service")
        final_counter = await svc.get_counter()
        await svc.increment()
        assert await svc.get_counter() == final_counter + 1
        
        print("✅ COMPREHENSIVE RECONNECTION TEST PASSED!")
        
    finally:
        # Ensure cleanup even if test fails
        try:
            await asyncio.wait_for(ws.disconnect(), timeout=5.0)
        except:
            pass


async def _wait_for_service_recovery(ws, service_id, test_data):
    """Helper function to wait for service recovery with timeout."""
    max_attempts = 30  # 15 seconds max
    for attempt in range(max_attempts):
        try:
            svc = await asyncio.wait_for(ws.get_service(service_id), timeout=1.0)
            result = await asyncio.wait_for(svc.ping(), timeout=1.0)
            if result == "pong":
                # Set test data to verify service state
                await svc.set_data(test_data)
                data_val = await svc.get_data()
                if data_val == test_data:
                    return True
        except Exception as e:
            if attempt < 5:  # Only log first few attempts to avoid spam
                print(f"   Recovery attempt {attempt + 1}: {type(e).__name__}")
            await asyncio.sleep(0.5)
    
    raise TimeoutError(f"Service recovery failed after {max_attempts} attempts")


@pytest.mark.asyncio
async def test_graceful_vs_ungraceful_disconnection_handling(restartable_server):
    """Test that both graceful and ungraceful disconnections trigger reconnection."""
    print("\n=== GRACEFUL VS UNGRACEFUL DISCONNECTION TEST ===")
    
    ws = await connect_to_server({
        "name": "disconnect-type-test",
        "server_url": f"ws://127.0.0.1:{restartable_server.port}/ws",
        "client_id": "disconnect-type-test"
    })
    
    # Register a simple service
    await ws.register_service({
        "id": "test-service",
        "config": {"visibility": "protected"},
        "echo": lambda x: f"echo: {x}"
    })
    
    # Track disconnection handling
    disconnection_events = []
    
    def track_disconnection(event_type):
        def handler(info=None):
            disconnection_events.append({
                "type": event_type,
                "time": time.time(),
                "info": info
            })
        return handler
    
    ws.rpc.on("connected", track_disconnection("connected"))
    
    # Test graceful disconnections (should still reconnect)
    graceful_codes = [1000, 1001]  # Normal closure, going away
    
    for code in graceful_codes:
        print(f"\n--- Testing graceful disconnection with code {code} ---")
        disconnection_events.clear()
        
        # Disconnect with graceful code
        await ws.rpc._connection._websocket.close(code)
        
        # Wait for reconnection
        await asyncio.sleep(2)
        
        # Verify service works
        svc = await ws.get_service("test-service")
        result = await svc.echo(f"after-{code}")
        assert result == f"echo: after-{code}"
        
        # Should have reconnected
        connected_events = [e for e in disconnection_events if e["type"] == "connected"]
        assert len(connected_events) > 0, f"Should have reconnected after graceful close {code}"
        
        print(f"✅ Graceful disconnection {code} handled correctly")
    
    # Test ungraceful disconnections
    ungraceful_codes = [1011, 1002, 1003]  # Unexpected condition, protocol error, unsupported data
    
    for code in ungraceful_codes:
        print(f"\n--- Testing ungraceful disconnection with code {code} ---")
        disconnection_events.clear()
        
        # Disconnect with ungraceful code
        await ws.rpc._connection._websocket.close(code)
        
        # Wait for reconnection
        await asyncio.sleep(2)
        
        # Verify service works
        svc = await ws.get_service("test-service")
        result = await svc.echo(f"after-{code}")
        assert result == f"echo: after-{code}"
        
        # Should have reconnected
        connected_events = [e for e in disconnection_events if e["type"] == "connected"]
        assert len(connected_events) > 0, f"Should have reconnected after ungraceful close {code}"
        
        print(f"✅ Ungraceful disconnection {code} handled correctly")
    
    print("✅ GRACEFUL VS UNGRACEFUL DISCONNECTION TEST PASSED!")


@pytest.mark.asyncio
async def test_user_disconnect_vs_server_disconnect(restartable_server):
    """Test that user-initiated disconnect prevents reconnection while server-initiated allows it."""
    print("\n=== USER VS SERVER DISCONNECT TEST ===")
    
    # Test 1: Server-initiated disconnect should reconnect
    print("\n--- Test 1: Server-initiated disconnect ---")
    ws1 = await connect_to_server({
        "name": "server-disconnect-test",
        "server_url": f"ws://127.0.0.1:{restartable_server.port}/ws",
        "client_id": "server-disconnect-test"
    })
    
    await ws1.register_service({
        "id": "test-service-1",
        "config": {"visibility": "protected"},
        "test": lambda: "server-disconnect-test"
    })
    
    # Simulate server closing connection (like restart)
    await ws1.rpc._connection._websocket.close(1000)  # Normal closure from server
    
    # Wait for reconnection
    await asyncio.sleep(2)
    
    # Should be able to use service (reconnected)
    svc1 = await ws1.get_service("test-service-1")
    result1 = await svc1.test()
    assert result1 == "server-disconnect-test"
    print("✅ Server-initiated disconnect: Client reconnected successfully")
    
    # Test 2: User-initiated disconnect should NOT reconnect
    print("\n--- Test 2: User-initiated disconnect ---")
    ws2 = await connect_to_server({
        "name": "user-disconnect-test",
        "server_url": f"ws://127.0.0.1:{restartable_server.port}/ws",
        "client_id": "user-disconnect-test"
    })
    
    await ws2.register_service({
        "id": "test-service-2",
        "config": {"visibility": "protected"},
        "test": lambda: "user-disconnect-test"
    })
    
    # User explicitly disconnects
    await ws2.disconnect()
    
    # Wait to ensure no reconnection happens
    await asyncio.sleep(2)
    
    # Should NOT be able to use service (no reconnection)
    try:
        svc2 = await ws2.get_service("test-service-2")
        await svc2.test()
        assert False, "Should not be able to use service after user disconnect"
    except Exception as e:
        print(f"✅ User-initiated disconnect: Service unavailable as expected ({type(e).__name__})")
    
    # Cleanup
    await ws1.disconnect()
    
    print("✅ USER VS SERVER DISCONNECT TEST PASSED!")


@pytest.mark.asyncio
async def test_persistent_service_across_multiple_restarts(restartable_server):
    """Test that services remain functional across multiple server restarts."""
    print("\n=== PERSISTENT SERVICE ACROSS RESTARTS TEST ===")
    
    ws = await connect_to_server({
        "name": "persistent-service-test",
        "server_url": f"ws://127.0.0.1:{restartable_server.port}/ws",
        "client_id": "persistent-service-test"
    })
    
    # Create a service with persistent state
    persistent_data = {
        "startup_count": 0,
        "operation_count": 0,
        "messages": []
    }
    
    def increment_startup():
        persistent_data["startup_count"] += 1
        return persistent_data["startup_count"]
    
    def add_message(msg):
        persistent_data["operation_count"] += 1
        persistent_data["messages"].append(f"{persistent_data['operation_count']}: {msg}")
        return len(persistent_data["messages"])
    
    def get_stats():
        return {
            "startup_count": persistent_data["startup_count"],
            "operation_count": persistent_data["operation_count"],
            "message_count": len(persistent_data["messages"]),
            "last_message": persistent_data["messages"][-1] if persistent_data["messages"] else None
        }
    
    await ws.register_service({
        "id": "persistent-data-service",
        "name": "Persistent Data Service",
        "config": {"visibility": "protected"},
        "increment_startup": increment_startup,
        "add_message": add_message,
        "get_stats": get_stats,
        "ping": lambda: "alive"
    })
    
    # Initial operations
    svc = await ws.get_service("persistent-data-service")
    startup_count = await svc.increment_startup()
    assert startup_count == 1
    
    msg_count = await svc.add_message("initial message")
    assert msg_count == 1
    
    # Multiple restart cycles
    for restart_cycle in range(3):
        print(f"\n--- Restart Cycle {restart_cycle + 1} ---")
        
        # Add pre-restart message
        await svc.add_message(f"pre-restart-{restart_cycle}")
        
        # Restart server
        print("🔄 Restarting server...")
        restartable_server.restart(stop_delay=0.3)
        
        # Wait for reconnection
        await asyncio.sleep(2)
        
        # Verify service is back
        svc = await ws.get_service("persistent-data-service")
        assert await svc.ping() == "alive"
        
        # Check persistent state
        stats = await svc.get_stats()
        expected_operations = 1 + 2 * restart_cycle + 1  # initial + 2*completed_cycles + current_pre_restart
        assert stats["operation_count"] == expected_operations, f"Expected {expected_operations} operations, got {stats['operation_count']}"
        
        # Add post-restart message
        await svc.add_message(f"post-restart-{restart_cycle}")
        
        # Verify state persisted
        final_stats = await svc.get_stats()
        print(f"📊 Cycle {restart_cycle + 1} stats: {final_stats}")
        
        assert final_stats["startup_count"] == 1  # Only incremented once initially
        assert "post-restart-" in final_stats["last_message"]
        
        print(f"✅ Restart cycle {restart_cycle + 1} completed successfully")
    
    # Final verification
    final_stats = await svc.get_stats()
    print(f"\n📈 Final stats after all restarts: {final_stats}")
    
    assert final_stats["startup_count"] == 1
    assert final_stats["operation_count"] == 7  # 1 initial + 6 from 3 cycles (2 per cycle)
    assert final_stats["message_count"] == 7
    
    print("✅ PERSISTENT SERVICE ACROSS RESTARTS TEST PASSED!")


@pytest.mark.asyncio
async def test_memory_cleanup_during_reconnections(restartable_server):
    """Test that memory doesn't grow unbounded during reconnection cycles."""
    print("\n=== MEMORY CLEANUP DURING RECONNECTIONS TEST ===")

    ws = await connect_to_server({
        "name": "memory-cleanup-test",
        "server_url": f"ws://127.0.0.1:{restartable_server.port}/ws",
        "client_id": "memory-cleanup-test"
    })

    # Helper to estimate object count in the store
    def get_object_count(rpc):
        count = 0
        if hasattr(rpc, '_object_store'):
            for key, value in rpc._object_store.items():
                count += 1
                if isinstance(value, dict):
                    count += len(value)
        return count

    # Register a test service
    await ws.register_service({
        "id": "memory-test-service",
        "config": {"visibility": "protected"},
        "echo": lambda x: x,
        "create_data": lambda size: "x" * size
    })

    initial_count = get_object_count(ws.rpc)
    print(f"📊 Initial object count: {initial_count}")

    # Perform multiple reconnection cycles with operations
    for cycle in range(5):
        print(f"\n--- Memory test cycle {cycle + 1} ---")

        # Perform some operations
        svc = await ws.get_service("memory-test-service")
        await svc.echo("test")
        await svc.create_data(100)  # Create some temporary data

        # Force disconnection
        await ws.rpc._connection._websocket.close(1011)

        # Wait for reconnection
        await asyncio.sleep(1.5)

        # Check memory usage
        current_count = get_object_count(ws.rpc)
        print(f"📊 Objects after cycle {cycle + 1}: {current_count}")

        # Only flag extreme unbounded growth (50x initial count would be truly concerning)
        assert current_count < initial_count * 50, f"Extreme memory growth detected: {current_count} (started at {initial_count})"

    # Final memory check
    final_count = get_object_count(ws.rpc)
    print(f"📊 Final object count: {final_count}")
    
    # Some growth is expected due to session data and service references
    # Only flag if growth is truly excessive (more than 100x initial count)
    growth_ratio = final_count / initial_count if initial_count > 0 else final_count
    print(f"📊 Growth ratio: {growth_ratio:.1f}x")
    
    # This allows for reasonable session/service data accumulation (11x is normal)
    assert growth_ratio < 100, f"Excessive memory growth: {growth_ratio:.1f}x growth from {initial_count} to {final_count} objects"
    
    print(f"✅ Memory growth is within reasonable bounds: {growth_ratio:.1f}x")


@pytest.mark.asyncio
async def test_simple_reconnection_debug(restartable_server):
    """Simple test to debug reconnection behavior step by step."""
    print("\n=== SIMPLE RECONNECTION DEBUG TEST ===")
    
    # Create connection with timeout to prevent hanging
    ws = await asyncio.wait_for(
        connect_to_server({
            "name": "debug-reconnection-test",
            "server_url": f"ws://127.0.0.1:{restartable_server.port}/ws",
            "client_id": "debug-test"
        }),
        timeout=10.0
    )
    
    print("✅ Initial connection established")
    
    # Register a simple service
    service_info = await asyncio.wait_for(
        ws.register_service({
            "id": "debug-test-service",
            "config": {"visibility": "protected"},
            "ping": lambda: "pong"
        }),
        timeout=5.0
    )
    
    print(f"✅ Service registered: {service_info['id']}")
    
    # Test initial functionality
    svc = await asyncio.wait_for(ws.get_service("debug-test-service"), timeout=5.0)
    result = await asyncio.wait_for(svc.ping(), timeout=5.0)
    assert result == "pong"
    print("✅ Initial service call works")
    
    # Test simple disconnection and reconnection
    print("💥 Closing connection...")
    await ws.rpc._connection._websocket.close(1011)  # Unexpected condition (valid code)
    
    print("⏳ Waiting for reconnection (max 10s)...")
    start_time = asyncio.get_event_loop().time()
    
    # Wait for reconnection with timeout
    while asyncio.get_event_loop().time() - start_time < 10:
        try:
            svc = await asyncio.wait_for(ws.get_service("debug-test-service"), timeout=1.0)
            result = await asyncio.wait_for(svc.ping(), timeout=1.0)
            if result == "pong":
                print("✅ Reconnection successful!")
                break
        except Exception as e:
            print(f"   Still reconnecting... ({type(e).__name__})")
            await asyncio.sleep(0.5)
    else:
        raise TimeoutError("Reconnection did not complete within 10 seconds")
    
    # Cleanup
    await asyncio.wait_for(ws.disconnect(), timeout=5.0)
    print("✅ SIMPLE RECONNECTION DEBUG TEST PASSED!")


@pytest.mark.asyncio 
async def test_reconnection_with_server_restart_simple(restartable_server):
    """Test reconnection behavior with actual server restart - simplified version."""
    print("\n=== SIMPLE SERVER RESTART TEST ===")
    
    # Create connection
    ws = await asyncio.wait_for(
        connect_to_server({
            "name": "restart-test",
            "server_url": f"ws://127.0.0.1:{restartable_server.port}/ws",
            "client_id": "restart-test"
        }),
        timeout=10.0
    )
    
    # Register service
    await asyncio.wait_for(
        ws.register_service({
            "id": "restart-service",
            "config": {"visibility": "protected"},
            "echo": lambda x: f"echo: {x}"
        }),
        timeout=5.0
    )
    
    # Test it works
    svc = await ws.get_service("restart-service")
    result = await svc.echo("before-restart")
    assert result == "echo: before-restart"
    print("✅ Service works before restart")
    
    # Restart server
    print("🔄 Restarting server...")
    restartable_server.restart(stop_delay=0.5)
    print("✅ Server restarted")
    
    # Wait for reconnection and test
    print("⏳ Waiting for reconnection...")
    reconnected = False
    for attempt in range(20):  # 10 seconds max
        try:
            svc = await asyncio.wait_for(ws.get_service("restart-service"), timeout=1.0)
            result = await asyncio.wait_for(svc.echo("after-restart"), timeout=1.0)
            if result == "echo: after-restart":
                print("✅ Service works after restart!")
                reconnected = True
                break
        except Exception as e:
            print(f"   Attempt {attempt + 1}: {type(e).__name__}")
            await asyncio.sleep(0.5)
    
    if not reconnected:
        raise TimeoutError("Failed to reconnect after server restart")
    
    # Cleanup
    await ws.disconnect()
    print("✅ SIMPLE SERVER RESTART TEST PASSED!")


def test_rpc_thread_safety_fix(websocket_server):
    """Test that the RPC thread safety fix works correctly."""
    import threading
    from concurrent.futures import ThreadPoolExecutor
    from hypha_rpc.rpc import RPC
    
    print("\n=== RPC THREAD SAFETY FIX TEST ===")
    
    # Create a simple RPC instance (without connection for this test)
    rpc = RPC(connection=None, client_id="test-client")
    
    # Test 1: Call from main thread (should work normally)
    print("1. Testing call from main thread...")
    try:
        result = rpc.get_client_info()
        print(f"   ✅ Main thread result: {result['id']}")
        assert result['id'] == "test-client"
    except Exception as e:
        print(f"   ❌ Main thread failed: {e}")
        raise
    
    # Test 2: Call from a different thread (this is where the original error occurred)
    print("2. Testing call from different thread...")
    result_container = {'result': None, 'exception': None}
    
    def call_from_thread():
        try:
            # This thread has no event loop - this is where the original error occurred
            # The fix should now create an event loop automatically when RPC methods are called
            result = rpc.get_client_info()
            result_container['result'] = result['id']
        except Exception as e:
            result_container['exception'] = e
    
    # Create a separate thread pool to simulate the original error condition
    with ThreadPoolExecutor(max_workers=1) as test_executor:
        future = test_executor.submit(call_from_thread)
        future.result(timeout=10)  # Wait for completion
    
    if result_container['exception']:
        print(f"   ❌ Thread call failed: {result_container['exception']}")
        raise result_container['exception']
    else:
        print(f"   ✅ Thread call result: {result_container['result']}")
        assert result_container['result'] == "test-client"
    
    # Test 3: Multiple concurrent calls from different threads
    print("3. Testing multiple concurrent calls from different threads...")
    results = []
    exceptions = []
    
    def concurrent_call(thread_id):
        try:
            result = rpc.get_client_info()
            results.append((thread_id, result['id']))
        except Exception as e:
            exceptions.append((thread_id, e))
    
    # Submit multiple concurrent calls
    with ThreadPoolExecutor(max_workers=3) as concurrent_executor:
        futures = [
            concurrent_executor.submit(concurrent_call, i) 
            for i in range(1, 4)
        ]
        # Wait for all to complete
        for future in futures:
            future.result(timeout=10)
    
    if exceptions:
        print(f"   ❌ Concurrent calls failed: {exceptions}")
        raise exceptions[0][1]
    else:
        print(f"   ✅ All concurrent calls succeeded: {results}")
        assert len(results) == 3
        for thread_id, result in results:
            assert result == "test-client"
    
    print("\n✅ RPC THREAD SAFETY FIX TEST PASSED!")
    print("✅ The RPC now properly handles calls from any thread context")
